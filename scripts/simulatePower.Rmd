---
title: "Power simulations"
author: "Benjamin Chan (chanb@ohsu.edu)"
date: `r Sys.Date()`
output: html_document
---

```{r setup, include=FALSE}
setwd("C:/Users/chanb/Box Sync/Share/BDP2-2 Horner-Johnson/scripts")
library(checkpoint)
library(knitr)
library(rmarkdown)
checkpoint("2018-04-01", use.knitr = TRUE)
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      fig.path = "../figures/", 
                      dpi = 300)
library(magrittr)
library(dplyr)
library(broom)
library(parallel)
library(doParallel)
library(ggplot2)
library(truncnorm)
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
Sys.time0 <- Sys.time()
```

## Simulation parameters

```{r}
N <- 500
S <- 5000
set.seed(as.integer(as.Date("2018-05-11")))
```

Full sample size is **`r sprintf("N = %d", N)`**.

Number of simulations is **`r sprintf("S = %d", S)`**.

The outcomes are **comprehension** and **influence**.


## Aim 1: Comprehension

```{r}
comprehension0 <- 0.5
effectSize <- 0.37
alpha <- 0.05
```

Comprehension is a dichotomous outcome.
With graphic **A**, comprehension is assumed to be **`r sprintf("%.00f%%", comprehension0 * 100)`**.
With graphic **B**, comprehension is assumed to be **`r sprintf("%.00f%%", (exp(effectSize) / (1 + exp(effectSize))) * 100)`**.

All subjects will have comprehension assessed with graphics A and B.
Order of presentation and message will be randomized.
Assumed test is McNemar's chi-square for paired proportions.
$H_0$ is there is no difference in the comprehension proportions between graphics A and B.

```{r comprehension}
order <-
  replicate(N * S, sample(c(1, 2), 2)) %>% 
  as.vector()
scenario <-
  replicate(N * S, sample(c("a", "b"), 2)) %>% 
  as.vector()
df <-
  expand.grid(sim = seq(S),
              subject = seq(N),
              graphic = c("A", "B")) %>% 
  bind_cols(data.frame(order)) %>% 
  bind_cols(data.frame(scenario)) %>% 
  mutate(scenario = factor(scenario, labels = c("a", "b"))) %>% 
  mutate(eta = 
           log(comprehension0 / (1 - comprehension0)) + 
           as.integer(graphic == "A") * 0.0  + 
           as.integer(graphic == "B") * effectSize) %>% 
  mutate(comprehension = rbinom(nrow(.), 1, exp(eta) / (1 + exp(eta)))) %>% 
  arrange(sim, subject, order) %>% 
  select(sim, subject, order, graphic, scenario, comprehension)
rm(comprehension0, order, scenario)
df %>% 
  filter(order == 1) %>% 
  group_by(order, graphic, scenario) %>% 
  summarize(n = n())
df %>% 
  group_by(graphic) %>% 
  summarize(y = sum(comprehension),
            n = n(),
            p = sum(comprehension) / n())

cores <- min(4, detectCores() - 1)
cl <- makeCluster(cores)
registerDoParallel(cl)
tests <- foreach (i = seq(S), .combine = rbind) %dopar% {
  require(magrittr)
  require(tidyr)
  require(dplyr)
  dfi <-
    df %>% 
    filter(sim == i) %>% 
    select(subject, graphic, comprehension) %>% 
    spread(graphic, comprehension)
  test <- mcnemar.test(dfi$A, dfi$B)
  data.frame(method = test$method,
             chisq = test$statistic,
             df = test$parameter,
             pvalue = test$p.value,
             sig = test$p.value < alpha)
}
stopCluster(cl)
tests %>% 
  summarize(samples = n(),
            truePos = sum(sig)) %>% 
  mutate(power = truePos / samples) %>% 
  mutate(sampleSize = N) %>% 
  kable()
tests %>% 
  ggplot(aes(x = chisq, fill = sig)) +
  ggtitle(sprintf("%d simulations of sample size %d", S, N)) +
  geom_histogram(alpha = 1/2) +
  scale_x_continuous(tests %>% pull(method) %>% as.character() %>% unique()) +
  scale_fill_discrete("", labels = c("False Neg", "True Pos"))
```


## Aim 2: Influence

```{r}
influence0 <- 0
sd0 <- 1.0
effectSizeB <- 0.65
effectSizeC <- 0.7
effectSizeD <- 0.75
alpha <- 0.05
```

Influence is a continuous outcome.
For analytic purposes, it will be scaled on a (-1, +1) continuum.
With video **A**, influence is assumed to be **`r sprintf("%.02f", influence0)`**.
With video **B**, influence is assumed to be **`r sprintf("%.00f%%", influence0 + effectSizeB)`**.
With video **C**, influence is assumed to be **`r sprintf("%.00f%%", influence0 + effectSizeC)`**.
With video **D**, influence is assumed to be **`r sprintf("%.00f%%", influence0 + effectSizeD)`**.
Standard deviation is assumed to be equal across video groups with value **`r sprintf("%.00f%%", sd0)`**

Since the metric is bounded by -1 and +1, a truncated normal distribution is simulated.
The simulated means will be different that the specified nominal means above.

```{r influence}
video <-
  replicate((N / 4) * S, sample(LETTERS[1:4], 4)) %>% 
  as.vector()
df <-
  expand.grid(subject = seq(N),
              sim = seq(S)) %>% 
  bind_cols(data.frame(video)) %>% 
  mutate(eta = 
           influence0 + 
           as.integer(video == "A") * 0.0 + 
           as.integer(video == "B") * effectSizeB + 
           as.integer(video == "C") * effectSizeC + 
           as.integer(video == "D") * effectSizeD) %>% 
  mutate(influence = rtruncnorm(nrow(.), a = -1, b = +1, mean = eta, sd = sd0)) %>% 
  arrange(sim, subject, video) %>% 
  select(sim, subject, video, eta, influence)
rm(influence0, sd0, video)
df %>%
  ggplot(aes(x = influence)) +
  geom_density(fill = "grey", alpha = 1/2) +
  scale_x_continuous("Influence, truncated normal random variable") +
  facet_wrap(~ video, ncol = 1)
dfSum <- 
  df %>% 
  group_by(sim, video) %>% 
  summarize(n = n(),
            eta = mean(eta),
            y = mean(influence),
            s = sd(influence),
            z = mean(influence) / sd(influence),
            cv = sd(influence) / mean(influence))
dfSum %>% 
  group_by(video) %>% 
  summarize(n = n(),
            meanInfluence = mean(y),
            meanSD = mean(s),
            meanZ = mean(z),
            meanCV = mean(cv),
            nominalEffectSize = mean(eta)) %>% 
  kable(digits = 3)
dfSum %>% 
  ggplot(aes(x = y)) +
  geom_density(fill = "grey", alpha = 1/2) +
  scale_x_continuous("Mean influence") +
  facet_wrap(~ video, ncol = 1)
dfSum %>% 
  ggplot(aes(x = s)) +
  geom_density(fill = "grey", alpha = 1/2) +
  scale_x_continuous("SD influence") +
  facet_wrap(~ video, ncol = 1)
dfSum %>% 
  ggplot(aes(x = z)) +
  geom_density(fill = "grey", alpha = 1/2) +
  scale_x_continuous("Mean influence in SD units") +
  facet_wrap(~ video, ncol = 1)

cores <- min(4, detectCores() - 1)
cl <- makeCluster(cores)
registerDoParallel(cl)
tests <- foreach (i = seq(S), .combine = rbind) %dopar% {
  require(magrittr)
  require(dplyr)
  require(broom)
  df %>% 
    filter(sim == i) %>% 
    lm(influence ~ video, data = .) %>% 
    tidy() %>% 
    mutate(sim = i) %>% 
    mutate(sig = p.value < 0.05)
}
stopCluster(cl)
tests %>% 
  filter(term != "(Intercept)") %>% 
  group_by(term) %>% 
  summarize(meanEstimate = mean(estimate),
            sdEstimate = sd(estimate),
            meanStatistic = mean(statistic),
            samples = n(),
            truePos = sum(sig)) %>% 
  mutate(power = truePos / samples) %>% 
  kable()
tests %>% 
  filter(term != "(Intercept)") %>% 
  ggplot(aes(x = estimate, fill = sig)) +
  geom_histogram(alpha = 1/2) +
  scale_fill_discrete("", labels = c("False Neg", "True Pos")) +
  facet_wrap(~ term, ncol = 1) +
  theme(legend.position = "top")
```


## Session summary

```{r}
list(completionDateTime = Sys.time(),
     executionTime = Sys.time() - Sys.time0,
     sessionInfo = sessionInfo())
```
