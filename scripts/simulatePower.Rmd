---
title: "Power simulations"
author: "Benjamin Chan (chanb@ohsu.edu)"
date: `r Sys.Date()`
output: html_document
---

```{r setup, include=FALSE}
setwd("C:/Users/chanb/Box Sync/Share/BDP2-2 Horner-Johnson/scripts")
library(checkpoint)
library(knitr)
library(rmarkdown)
checkpoint("2018-04-01", use.knitr = TRUE)
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      fig.path = "../figures/", 
                      dpi = 300)
library(magrittr)
library(dplyr)
library(broom)
library(parallel)
library(doParallel)
library(ggplot2)
library(truncnorm)
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
Sys.time0 <- Sys.time()
```

## Generate data

```{r}
N <- 500
S <- 1000
set.seed(as.integer(as.Date("2018-05-11")))
```

Study design is a two-factor, full factorial randomization.
The factors are **framing** and the **message** of the intervention.
Each factor has **3** levels.

Full sample size is **`r sprintf("N = %d", N)`**.

Number of simulations is **`r sprintf("S = %d", S)`**.

The outcomes are **comprehension** and **influence**.

```{r}
comprehension0 <- 0.5
influence0 <- 0
sd0 <- 1.0
```

Comprehension is a dichotomous outcome.
Baseline comprehension is assumed to be **`r sprintf("%.00f%%", comprehension0 * 100)`**.

Influence is a continuous outcome.
It represents pre-post change on a scale.
For analytic purposes, it will be scaled on a (-1, +1) continuum.
Baseline influence is assumed to be **`r sprintf("%.02f", influence0)`**.

```{r generateData}
df <- 
  expand.grid(framing = c("A", "B", "C"),
              message = c("X", "Y", "Z"),
              id = seq(round(N / 9)),
              sample = seq(S)) %>% 
  mutate(eta1 = 
           log(comprehension0 / (1 - comprehension0)) + 
           as.integer(framing == "A") *  0.0  + 
           as.integer(framing == "B") *  0.55 + 
           as.integer(framing == "C") *  0.65 + 
           as.integer(message == "X") *  0.0  + 
           as.integer(message == "Y") *  0.60 + 
           as.integer(message == "Z") *  0.70) %>% 
  mutate(comprehension = rbinom(nrow(.), 1, exp(eta1) / (1 + exp(eta1)))) %>% 
  mutate(eta2 = 
           influence0 + 
           as.integer(framing == "A") * 0.0 + 
           as.integer(framing == "B") * 0.50 + 
           as.integer(framing == "C") * 0.58 + 
           as.integer(message == "X") * 0.0 + 
           as.integer(message == "Y") * 0.54 + 
           as.integer(message == "Z") * 0.62) %>% 
  mutate(influence = rtruncnorm(nrow(.), a = -1, b = +1, mean = eta2, sd = sd0))
df %>%
  mutate(comprehension = as.logical(comprehension)) %>% 
  ggplot(aes(x = comprehension)) +
  geom_bar(color = "black", fill = "grey", alpha = 1/2) +
  scale_x_discrete("Comprehension, binomial random variable") +
  facet_grid(message ~ framing)
df %>%
  ggplot(aes(x = influence)) +
  geom_density(fill = "grey", alpha = 1/2) +
  scale_x_continuous("Influence, truncated normal random variable") +
  facet_grid(message ~ framing)
dfSum <- 
  df %>% 
  group_by(framing, message, sample) %>% 
  summarize(n = n(),
            eta1 = mean(eta1),
            y1 = sum(comprehension),
            p1 = sum(comprehension) / n(),
            eta2 = mean(eta2),
            y2 = mean(influence),
            s2 = sd(influence),
            cv2 = sd(influence) / mean(influence))
dfSum %>% 
  group_by(framing, message) %>% 
  summarize(n = n(),
            meanComprehension = mean(p1),
            nominalOddsRatio = exp(mean(eta1)),
            nominalRiskRatio = exp(mean(eta1)) / (1 - comprehension0 + (comprehension0 * exp(mean(eta1)))),
            nominalRiskDiff = mean(p1) - mean(p1) / (exp(mean(eta1)) / (1 - comprehension0 + (comprehension0 * exp(mean(eta1))))),
            meanInfluence = mean(y2),
            meanSD = mean(s2),
            meanCV = mean(cv2),
            nominalEffectSize = mean(eta2)) %>% 
  select(-nominalOddsRatio) %>% 
  kable(digits = 3)
dfSum %>% 
  ggplot(aes(x = p1)) +
  geom_density(fill = "grey", alpha = 1/2) +
  scale_x_continuous("Comprehension") +
  facet_grid(message ~ framing)
dfSum %>% 
  ggplot(aes(x = y2)) +
  geom_density(fill = "grey", alpha = 1/2) +
  scale_x_continuous("Mean influence") +
  facet_grid(message ~ framing)
dfSum %>% 
  ggplot(aes(x = s2)) +
  geom_density(fill = "grey", alpha = 1/2) +
  scale_x_continuous("SD influence") +
  facet_grid(message ~ framing)
```

## Aim 1: Comprehension

```{r}
comprehension0 <- 0.5
effectSize <- 0.37
alpha <- 0.05
```

Comprehension is a dichotomous outcome.
With graphic **A**, comprehension is assumed to be **`r sprintf("%.00f%%", comprehension0 * 100)`**.
With graphic **B**, comprehension is assumed to be **`r sprintf("%.00f%%", (exp(effectSize) / (1 + exp(effectSize))) * 100)`**.

All subjects will have comprehension assessed with graphics A and B.
Order of presentation and message will be randomized.
Assumed test is McNemar's chi-square for paired proportions.
$H_0$ is there is no difference in the comprehension proportions between graphics A and B.

```{r comprehension}
first <- sample(c(1, 2), N * S, replace = TRUE)
second <- 3 - first
order <- c(first, second)
first <- sample(c(1, 2), N * S, replace = TRUE)
second <- 3 - first
scenario <- c(first, second)
df <-
  expand.grid(sim = seq(S),
              subject = seq(N),
              graphic = c("A", "B")) %>% 
  bind_cols(data.frame(order)) %>% 
  bind_cols(data.frame(scenario)) %>% 
  mutate(scenario = factor(scenario, labels = c("a", "b"))) %>% 
  mutate(eta = 
           log(comprehension0 / (1 - comprehension0)) + 
           as.integer(graphic == "A") * 0.0  + 
           as.integer(graphic == "B") * effectSize) %>% 
  mutate(comprehension = rbinom(nrow(.), 1, exp(eta) / (1 + exp(eta)))) %>% 
  arrange(sim, subject, order) %>% 
  select(sim, subject, order, graphic, scenario, comprehension)
rm(comprehension0, first, second, order, scenario)
df %>% 
  filter(order == 1) %>% 
  group_by(order, graphic, scenario) %>% 
  summarize(n = n())
df %>% 
  group_by(graphic) %>% 
  summarize(y = sum(comprehension),
            n = n(),
            p = sum(comprehension) / n())

cores <- min(4, detectCores() - 1)
cl <- makeCluster(cores)
registerDoParallel(cl)
tests <- foreach (i = seq(S), .combine = rbind) %dopar% {
  require(magrittr)
  require(tidyr)
  require(dplyr)
  dfi <-
    df %>% 
    filter(sim == i) %>% 
    select(subject, graphic, comprehension) %>% 
    spread(graphic, comprehension)
  test <- mcnemar.test(dfi$A, dfi$B)
  data.frame(method = test$method,
             chisq = test$statistic,
             df = test$parameter,
             pvalue = test$p.value,
             sig = test$p.value < alpha)
}
stopCluster(cl)
tests %>% 
  summarize(samples = n(),
            truePos = sum(sig)) %>% 
  mutate(power = truePos / samples) %>% 
  mutate(sampleSize = N) %>% 
  kable()
tests %>% 
  ggplot(aes(x = chisq, fill = sig)) +
  geom_histogram(alpha = 1/2) +
  scale_x_continuous(tests %>% pull(method) %>% as.character() %>% unique()) +
  scale_fill_discrete("", labels = c("False Neg", "True Pos"))
```


## Aim 2: Influence

```{r influence}
cores <- min(4, detectCores() - 1)
cl <- makeCluster(cores)
registerDoParallel(cl)
simBetas <- foreach (i = seq(S), .combine = rbind) %dopar% {
  require(magrittr)
  require(dplyr)
  require(broom)
  df %>% 
    filter(sample == i) %>% 
    lm(influence ~ framing + message, data = .) %>% 
    tidy() %>% 
    mutate(sim = i)
}
stopCluster(cl)
power <- 
  simBetas %>% 
  filter(term != "(Intercept)") %>% 
  mutate(sig = p.value < 0.05)
power %>% 
  group_by(term) %>% 
  summarize(samples = n(),
            truePos = sum(sig)) %>% 
  mutate(power = truePos / samples) %>% 
  kable()
power %>% 
  ggplot(aes(x = estimate, fill = sig)) +
  geom_histogram(alpha = 1/2) +
  scale_fill_discrete("", labels = c("False Neg", "True Pos")) +
  facet_wrap(~ term)
```


## Session summary

```{r}
list(completionDateTime = Sys.time(),
     executionTime = Sys.time() - Sys.time0,
     sessionInfo = sessionInfo())
```
